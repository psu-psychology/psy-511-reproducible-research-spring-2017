
@article{goodman_what_2016,
	title = {What does research reproducibility mean?},
	volume = {8},
	copyright = {Copyright © 2016, American Association for the Advancement of Science},
	issn = {1946-6234, 1946-6242},
	url = {http://stm.sciencemag.org/content/8/341/341ps12},
	doi = {10.1126/scitranslmed.aaf5027},
	abstract = {The language and conceptual framework of “research reproducibility” are nonstandard and unsettled across the sciences. In this Perspective, we review an array of explicit and implicit definitions of reproducibility and related terminology, and discuss how to avoid potential misunderstandings when these terms are used as a surrogate for “truth.”
The language and conceptual framework of “research reproducibility” are nonstandard and unsettled across the sciences.
The language and conceptual framework of “research reproducibility” are nonstandard and unsettled across the sciences.},
	language = {en},
	number = {341},
	urldate = {2016-10-09},
	journal = {Science Translational Medicine},
	author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
	month = jun,
	year = {2016},
	pmid = {27252173},
	pages = {341ps12--341ps12},
	file = {Full Text PDF:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/M2JX5V9V/Goodman et al. - 2016 - What does research reproducibility mean.pdf:application/pdf;Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/TNSTI5G9/341ps12.html:text/html}
}


@article{collaboration_estimating_2015,
	title = {Estimating the reproducibility of psychological},
	volume = {349},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/content/349/6251/aac4716},
	doi = {10.1126/science.aac4716},
	abstract = {Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.
INTRODUCTION Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.
RATIONALE There is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.
RESULTS We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P {\textless} .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.
CONCLUSION No single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here. Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that “we already know this” belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know. Related ResourcesIn Science Magazine Podcasts Science Podcast: 28 August Show Science 28 August 2015: 999.In Depth Reproducibility Many psychology papers fail replication test John BohannonScience 28 August 2015: 910-911.Policy Forum Scientific Standards Promoting an open research culture B. A. Nosek et al.Science 26 June 2015: 1422-1425.Editorial EDITORIAL: Solving reproducibility Stuart BuckScience 26 June 2015: 1403.More related articles... View larger version: In this page In a new window Download PowerPoint Slide for Teaching Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.
Empirically analyzing empirical evidence
One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.
Science, this issue 10.1126/science.aac4716},
	language = {en},
	number = {6251},
	urldate = {2015-08-28},
	journal = {Science},
	author = {Collaboration, Open Science},
	month = aug,
	year = {2015},
	pages = {aac4716},
	file = {Full Text PDF:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/UHASJEE8/Collaboration - 2015 - Estimating the reproducibility of psychological.pdf:application/pdf;Full Text PDF:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/M2DUJAI7/Collaboration - 2015 - Estimating the reproducibility of psychological.pdf:application/pdf;Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/SI9HSIGX/Collaboration - 2015 - Estimating the reproducibility of psychological.html:text/html;Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/IN75VC96/aac4716.html:text/html}
}


@article{gilbert_comment_2016,
	title = {Comment on “{Estimating} the reproducibility of psychological science”},
	volume = {351},
	copyright = {Copyright © 2016, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/351/6277/1037.2},
	doi = {10.1126/science.aad7243},
	abstract = {A paper from the Open Science Collaboration (Research Articles, 28 August 2015, aac4716) attempting to replicate 100 published studies suggests that the reproducibility of psychological science is surprisingly low. We show that this article contains three statistical errors and provides no support for such a conclusion. Indeed, the data are consistent with the opposite conclusion, namely, that the reproducibility of psychological science is quite high.},
	language = {en},
	number = {6277},
	urldate = {2016-03-27},
	journal = {Science},
	author = {Gilbert, Daniel T. and King, Gary and Pettigrew, Stephen and Wilson, Timothy D.},
	month = mar,
	year = {2016},
	pmid = {26941311},
	pages = {1037--1037},
	file = {Full Text PDF:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/2IMDZZE6/Gilbert et al. - 2016 - Comment on “Estimating the reproducibility of psyc.pdf:application/pdf;Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/H8PEE6R2/1037.html:text/html}
}


@article{nosek_promoting_2015,
	title = {Promoting an open research culture},
	volume = {348},
	copyright = {Copyright © 2015, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/348/6242/1422},
	doi = {10.1126/science.aab2374},
	abstract = {Author guidelines for journals could help to promote transparency, openness, and reproducibility
Author guidelines for journals could help to promote transparency, openness, and reproducibility},
	language = {en},
	number = {6242},
	urldate = {2016-09-08},
	journal = {Science},
	author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. Levy and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
	month = jun,
	year = {2015},
	pmid = {26113702},
	pages = {1422--1425},
	file = {Nosek et al. - 2015 - Promoting an open research culture.pdf:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/UZE4ESDI/Nosek et al. - 2015 - Promoting an open research culture.pdf:application/pdf;Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/6CI232F3/1422.full.html:text/html;Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/KICS687H/1422.html:text/html}
}

@article{lash2015declining,
  title={Declining the Transparency and Openness Promotion Guidelines},
  author={Lash, Timothy L},
  url={http://journals.lww.com/epidem/Fulltext/2015/11000/Declining_the_Transparency_and_Openness_Promotion.1.aspx},
  journal={Epidemiology},
  volume={26},
  number={6},
  pages={779--780},
  year={2015},
  publisher={LWW}
}


@article{baker_over_2015,
	title = {Over half of psychology studies fail reproducibility test},
	url = {http://www.nature.com/news/over-half-of-psychology-studies-fail-reproducibility-test-1.18248},
	doi = {10.1038/nature.2015.18248},
	abstract = {Largest replication study to date casts doubt on many published positive results.},
	urldate = {2017-01-02},
	journal = {Nature News},
	author = {Baker, Monya},
	month = aug,
	year = {2015},
	file = {Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/2JGJAIVI/over-half-of-psychology-studies-fail-reproducibility-test-1.html:text/html}
}

@article{miguel_promoting_2014,
	title = {Promoting {Transparency} in {Social} {Science} {Research}},
	volume = {343},
	issn = {0036-8075, 1095-9203},
	url = {http://www.sciencemag.org/content/343/6166/30},
	doi = {10.1126/science.1245317},
	language = {en},
	number = {6166},
	urldate = {2015-06-15},
	journal = {Science},
	author = {Miguel, E. and Camerer, C. and Casey, K. and Cohen, J. and Esterling, K. M. and Gerber, A. and Glennerster, R. and Green, D. P. and Humphreys, M. and Imbens, G. and Laitin, D. and Madon, T. and Nelson, L. and Nosek, B. A. and Petersen, M. and Sedlmayr, R. and Simmons, J. P. and Simonsohn, U. and Laan, M. Van der},
	month = jan,
	year = {2014},
	pmid = {24385620},
	pages = {30--31},
	file = {Full Text PDF:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/RAZJHJKX/Miguel et al. - 2014 - Promoting Transparency in Social Science Research.pdf:application/pdf;Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/N5T9BZP2/Miguel et al. - 2014 - Promoting Transparency in Social Science Research.html:text/html}
}


@article{hauser_retracted:_2002,
	title = {{RETRACTED}: {Rule} learning by cotton-top tamarins},
	volume = {86},
	issn = {0010-0277},
	shorttitle = {{RETRACTED}},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027702001397},
	doi = {10.1016/S0010-0277(02)00139-7},
	abstract = {This article has been retracted: please see Elsevier Policy on Article Withdrawal (http://www.elsevier.com/locate/withdrawalpolicy). This article has been retracted at the request of the authors. An internal investigation at Harvard University of the reported research found that the data do not support the reported findings. The authors are therefore retracting this article. M. Hauser accepts responsibility for the error.},
	number = {1},
	urldate = {2017-01-03},
	journal = {Cognition},
	author = {Hauser, Marc D. and Weiss, Daniel and Marcus, Gary},
	month = nov,
	year = {2002},
	pages = {B15--B22}
}


@article{saffran_grammatical_2008,
	title = {Grammatical pattern learning by human infants and cotton-top tamarin monkeys},
	volume = {107},
	issn = {0010-0277},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027707002697},
	doi = {10.1016/j.cognition.2007.10.010},
	abstract = {There is a surprising degree of overlapping structure evident across the languages of the world. One factor leading to cross-linguistic similarities may be constraints on human learning abilities. Linguistic structures that are easier for infants to learn should predominate in human languages. If correct, then (a) human infants should more readily acquire structures that are consistent with the form of natural language, whereas (b) non-human primates’ patterns of learning should be less tightly linked to the structure of human languages. Prior experiments have not directly compared laboratory-based learning of grammatical structures by human infants and non-human primates, especially under comparable testing conditions and with similar materials. Five experiments with 12-month-old human infants and adult cotton-top tamarin monkeys addressed these predictions, employing comparable methods (familiarization–discrimination) and materials. Infants rapidly acquired complex grammatical structures by using statistically predictive patterns, failing to learn structures that lacked such patterns. In contrast, the tamarins only exploited predictive patterns when learning relatively simple grammatical structures. Infant learning abilities may serve both to facilitate natural language acquisition and to impose constraints on the structure of human languages.},
	number = {2},
	urldate = {2017-01-03},
	journal = {Cognition},
	author = {Saffran, Jenny and Hauser, Marc and Seibel, Rebecca and Kapfhamer, Joshua and Tsao, Fritz and Cushman, Fiery},
	month = may,
	year = {2008},
	keywords = {Grammar learning, Infants, monkeys, Statistical learning},
	pages = {479--500}
}


@article{hauser_rhesus_2007,
	title = {Rhesus monkeys correctly read the goal-relevant gestures of a human agent},
	volume = {274},
	copyright = {© 2007 The Royal Society},
	issn = {0962-8452, 1471-2954},
	url = {http://rspb.royalsocietypublishing.org/content/274/1620/1913},
	doi = {10.1098/rspb.2007.0586},
	abstract = {When humans point, they reveal to others their underlying intent to communicate about some distant goal. A controversy has recently emerged based on a broad set of comparative and phylogenetically relevant data. In particular, whereas chimpanzees (Pan troglodytes) have difficulty in using human-generated communicative gestures and actions such as pointing and placing symbolic markers to find hidden rewards, domesticated dogs (Canis familiaris) and silver foxes (Urocyon cinereoargenteus) readily use such gestures and markers. These comparative data have led to the hypothesis that the capacity to infer communicative intent in dogs and foxes has evolved as a result of human domestication. Though this hypothesis has met with challenges, due in part to studies of non-domesticated, non-primate animals, there remains the fundamental question of why our closest living relatives, the chimpanzees, together with other non-human primates, generally fail to make inferences about a target goal of an agent's communicative intent. Here, we add an important wrinkle to this phylogenetic pattern by showing that free-ranging rhesus monkeys (Macaca mulatta) draw correct inferences about the goals of a human agent, using a suite of communicative gestures to locate previously concealed food. Though domestication and human enculturation may play a significant role in tuning up the capacity to infer intentions from communicative gestures, these factors are not necessary.},
	language = {en},
	number = {1620},
	urldate = {2017-01-03},
	journal = {Proceedings of the Royal Society of London B: Biological Sciences},
	author = {Hauser, Marc D. and Glynn, David and Wood, Justin},
	month = aug,
	year = {2007},
	pmid = {17540661},
	pages = {1913--1918},
	file = {Full Text PDF:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/U7ZN48NB/Hauser et al. - 2007 - Rhesus monkeys correctly read the goal-relevant ge.pdf:application/pdf;Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/TH9XRR2C/1913.html:text/html}
}


@article{wood_perception_2007,
	title = {The {Perception} of {Rational}, {Goal}-{Directed} {Action} in {Nonhuman} {Primates}},
	volume = {317},
	copyright = {American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/317/5843/1402},
	doi = {10.1126/science.1144663},
	abstract = {Humans are capable of making inferences about other individuals' intentions and goals by evaluating their actions in relation to the constraints imposed by the environment. This capacity enables humans to go beyond the surface appearance of behavior to draw inferences about an individual's mental states. Presently unclear is whether this capacity is uniquely human or is shared with other animals. We show that cotton-top tamarins, rhesus macaques, and chimpanzees all make spontaneous inferences about a human experimenter's goal by attending to the environmental constraints that guide rational action. These findings rule out simple associative accounts of action perception and show that our capacity to infer rational, goal-directed action likely arose at least as far back as the New World monkeys, some 40 million years ago.
Apes, as well as New and Old World monkeys, can analyze goal-directed actions and infer the underlying rationale.
Apes, as well as New and Old World monkeys, can analyze goal-directed actions and infer the underlying rationale.},
	language = {en},
	number = {5843},
	urldate = {2017-01-03},
	journal = {Science},
	author = {Wood, Justin N. and Glynn, David D. and Phillips, Brenda C. and Hauser, Marc D.},
	month = sep,
	year = {2007},
	pmid = {17823353},
	pages = {1402--1405},
	file = {Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/U679G9UK/1402.html:text/html}
}


@article{hadley_wickham_tidy_2014,
	title = {Tidy {Data}},
	volume = {59},
	url = {https://www.jstatsoft.org/article/view/v059i10},
	doi = {10.18637/jss.v059.i10},
	abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
	number = {10},
	urldate = {2016-11-19},
	journal = {Journal of Statistical Software},
	author = {Wickham, Hadley},
	year = {2014},
	file = {Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/XWSTDFGN/Tidy Data  Wickham  Journal of Statistical Softw.html:text/html}
}

@article{szucs_empirical_2016,
	title = {Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature},
	copyright = {© 2016, Published by Cold Spring Harbor Laboratory Press. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {http://biorxiv.org/content/early/2016/08/25/071530},
	doi = {10.1101/071530},
	abstract = {We have empirically assessed the distribution of published effect sizes and estimated power by extracting more than 100,000 statistical records from about 10,000 cognitive neuroscience and psychology papers published during the past 5 years. The reported median effect size was d=0.93 (inter-quartile range: 0.64-1.46) for nominally statistically significant results and d=0.24 (0.11-0.42) for non-significant results. Median power to detect small, medium and large effects was 0.12, 0.44 and 0.73, reflecting no improvement through the past half-century. Power was lowest for cognitive neuroscience journals. 14\% of papers reported some statistically significant results, although the respective F statistic and degrees of freedom proved that these were non-significant; p value errors positively correlated with journal impact factors. False report probability is likely to exceed 50\% for the whole literature. In light of our findings the recently reported low replication success in psychology is realistic and worse performance may be expected for cognitive neuroscience.},
	language = {en},
	urldate = {2016-10-02},
	journal = {bioRxiv},
	author = {Szucs, Denes and Ioannidis, John PA},
	month = aug,
	year = {2016},
	pages = {071530},
	file = {Full Text PDF:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/VS2PGZCM/Szucs and Ioannidis - 2016 - Empirical assessment of published effect sizes and.pdf:application/pdf;Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/HUEFQC2G/071530.html:text/html}
}

@article{macwhinney_stepsystem_2001,
	title = {{STEP}—{A} {System} for {Teaching} {Experimental} {Psychology} using {E}-{Prime}},
	volume = {33},
	issn = {0743-3808, 1532-5970},
	url = {https://link.springer.com/article/10.3758/BF03195379},
	doi = {10.3758/BF03195379},
	abstract = {Students in psychology need to learn to design and analyze their own experiments. However, software that allows students to build experiments on their own has been limited in a variety of ways. The shipping of the first full release of the E-Prime system later this year will open up a new opportunity for addressing this problem. Because E-Prime promises to become the standard for building experiments in psychology, it is now possible to construct a Web-based resource that uses E-Prime as the delivery engine for a wide variety of instructional materials. This new system, funded by the National Science Foundation, is called STEP (System for the Teaching of Experimental Psychology). The goal of the STEP Project is to provide instructional materials that will facilitate the use of E-Prime in various learning contexts. We are now compiling a large set of classic experiments implemented in E-Prime and available over the Internet from http://step.psy.cmu.edu. The Web site also distributes instructional materials for building courses in experimental psychology based on E-Prime.},
	language = {en},
	number = {2},
	urldate = {2017-03-07},
	journal = {Behavior Research Methods, Instruments, \& Computers},
	author = {MacWhinney, Brian and James, James St and Schunn, Chris and Li, Ping and Schneider, Walter},
	month = may,
	year = {2001},
	pages = {287--296},
	file = {Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/MKTTTDFQ/MacWhinney et al. - 2001 - STEP—A System for Teaching Experimental Psychology.html:text/html}
}

@article{tran_online_2017,
	title = {Online recruitment and testing of infants with {Mechanical} {Turk}},
	volume = {156},
	issn = {0022-0965},
	url = {http://www.sciencedirect.com/science/article/pii/S0022096516302909},
	doi = {10.1016/j.jecp.2016.12.003},
	abstract = {Testing infants in the laboratory is expensive in time and money; consequently, many studies are underpowered, reducing their reproducibility. We investigated whether the online platform, Amazon Mechanical Turk (MTurk), could be used as a resource to more easily recruit and measure the behavior of infant populations. Using a looking time paradigm, with users’ webcams we recorded how long infants aged 5 to 8 months attended while viewing children’s television programs. We found that infants (N = 57) were more reliably engaged by some movies than by others and that the most engaging movies could maintain attention for approximately 70\% of a 10- to 13-min period. We then identified the cinematic features within the movies. Faces, singing-and-rhyming, and camera zooms were found to increase infant attention. Together, we established that MTurk can be used as a rapid tool for effectively recruiting and testing infants.},
	urldate = {2017-03-06},
	journal = {Journal of Experimental Child Psychology},
	author = {Tran, Michelle and Cabral, Laura and Patel, Ronak and Cusack, Rhodri},
	month = apr,
	year = {2017},
	keywords = {Amazon Mechanical Turk, Crowdsourcing, Infant behavior, Online research},
	pages = {168--178},
	file = {ScienceDirect Full Text PDF:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/43BN5B3U/Tran et al. - 2017 - Online recruitment and testing of infants with Mec.pdf:application/pdf;ScienceDirect Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/FK8JNIVS/Tran et al. - 2017 - Online recruitment and testing of infants with Mec.html:text/html}
}

@article{vasilevsky_reproducibility_2013,
	title = {On the reproducibility of science: unique identification of research resources in the biomedical literature},
	volume = {1},
	issn = {2167-8359},
	shorttitle = {On the reproducibility of science},
	url = {https://peerj.com/articles/148},
	doi = {10.7717/peerj.148},
	abstract = {Scientific reproducibility has been at the forefront of many news stories and there exist numerous initiatives to help address this problem. We posit that a contributor is simply a lack of specificity that is required to enable adequate research reproducibility. In particular, the inability to uniquely identify research resources, such as antibodies and model organisms, makes it difficult or impossible to reproduce experiments even where the science is otherwise sound. In order to better understand the magnitude of this problem, we designed an experiment to ascertain the “identifiability” of research resources in the biomedical literature. We evaluated recent journal articles in the fields of Neuroscience, Developmental Biology, Immunology, Cell and Molecular Biology and General Biology, selected randomly based on a diversity of impact factors for the journals, publishers, and experimental method reporting guidelines. We attempted to uniquely identify model organisms (mouse, rat, zebrafish, worm, fly and yeast), antibodies, knockdown reagents (morpholinos or RNAi), constructs, and cell lines. Specific criteria were developed to determine if a resource was uniquely identifiable, and included examining relevant repositories (such as model organism databases, and the Antibody Registry), as well as vendor sites. The results of this experiment show that 54\% of resources are not uniquely identifiable in publications, regardless of domain, journal impact factor, or reporting requirements. For example, in many cases the organism strain in which the experiment was performed or antibody that was used could not be identified. Our results show that identifiability is a serious problem for reproducibility. Based on these results, we provide recommendations to authors, reviewers, journal editors, vendors, and publishers. Scientific efficiency and reproducibility depend upon a research-wide improvement of this substantial problem in science today.},
	language = {en},
	urldate = {2017-03-07},
	journal = {PeerJ},
	author = {Vasilevsky, Nicole A. and Brush, Matthew H. and Paddock, Holly and Ponting, Laura and Tripathy, Shreejoy J. and LaRocca, Gregory M. and Haendel, Melissa A.},
	month = sep,
	year = {2013},
	pages = {e148},
	file = {Full Text PDF:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/KAVBHSJR/Vasilevsky et al. - 2013 - On the reproducibility of science unique identifi.pdf:application/pdf;Snapshot:/Users/rick/Library/Application Support/Zotero/Profiles/isqcn0ks.default/zotero/storage/ADZ76W7D/148.html:text/html}
}
@misc{https://doi.org/10.17910/B7.272,
  doi = {10.17910/B7.272},
  url = {https://doi.org/10.17910/B7.272},
  author = {Motta-Mena, Natalie V. and Scherf, Kathryn Suzanne},
  publisher = {Databrary},
  title = {Pubertal development shapes perception of complex facial expressions},
  year = {2016}
}
@article{gilmore-adolph-video-2017,
  url = {http://osf.io/3kvp7},
  title = {Video can make science more open, transparent, robust, and reproducible},
  author = {Gilmore, R. O. and Adolph, K. E.},
  year = {2017},
  month = {February},
  date = {7}
}